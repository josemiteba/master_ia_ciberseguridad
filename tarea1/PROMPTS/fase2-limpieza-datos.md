# Fase 2: Limpieza y Preprocesamiento

## ğŸ¯ **Objetivo**
Limpiar los datos extraÃ­dos eliminando duplicados, manejando valores nulos y detectando outliers, preservando seÃ±ales de ataques legÃ­timos.

## ğŸ¤– **Agente Principal**
```
Use cybersecurity-data-cleaner to clean and preprocess the extracted network traffic data
```

## ğŸ§¹ **Tareas de Limpieza**

### 1. **Valores Nulos y VacÃ­os**
- **IPs malformadas**: Eliminar registros con IPs invÃ¡lidas
- **Timestamps faltantes**: Eliminar registros sin tiempo
- **Puertos vacÃ­os**: Rellenar con 0 o mantener NULL
- **Campos opcionales**: dns_query, http_host, http_path, user_agent pueden ser NULL

### 2. **ValidaciÃ³n de Formatos**
```python
# Validar IPs
import ipaddress
def validate_ip(ip):
    try:
        ipaddress.IPv4Address(ip)
        return True
    except:
        return False

# Validar puertos (0-65535)
def validate_port(port):
    return 0 <= int(port) <= 65535 if port else True
```

### 3. **DetecciÃ³n de Outliers**
**IMPORTANTE**: En ciberseguridad, los outliers pueden ser ataques legÃ­timos
- **Mantener**: Conexiones muy frecuentes (posible fuerza bruta)
- **Mantener**: Puertos no estÃ¡ndar (posible C2)
- **Mantener**: Paquetes muy grandes o muy pequeÃ±os
- **Eliminar**: Solo si son errores tÃ©cnicos evidentes

### 4. **EliminaciÃ³n de Duplicados**
```python
# Duplicados exactos (todas las columnas)
df = df.drop_duplicates()

# Duplicados de flujo (mismo src_ip, dst_ip, src_port, dst_port en ventana de 1 segundo)
df = df.drop_duplicates(subset=['src_ip', 'dst_ip', 'src_port', 'dst_port'], 
                       keep='first')
```

## ğŸ› ï¸ **TecnologÃ­a**
- **LibrerÃ­a principal**: `pandas` para manipulaciÃ³n de datos
- **ValidaciÃ³n**: `ipaddress` para validar IPs
- **DetecciÃ³n outliers**: `scipy.stats` para z-score, IQR

## âš ï¸ **Reglas de Negocio**
1. **NO eliminar** trÃ¡fico sospechoso que pueda ser malware
2. **Preservar** orden cronolÃ³gico de eventos
3. **Documentar** todas las decisiones de limpieza
4. **Mantener** al menos 80% de los datos originales

## ğŸ“Š **MÃ©tricas de Calidad**
```python
# Reporte de limpieza
print(f"Registros originales: {original_count}")
print(f"Registros despuÃ©s de limpieza: {clean_count}")
print(f"Porcentaje conservado: {clean_count/original_count*100:.1f}%")
print(f"Valores nulos por columna:")
print(df.isnull().sum())
```

## ğŸ“‹ **Entregable**
- Archivo `datos_limpios.csv` con datos preprocesados
- Reporte de limpieza con estadÃ­sticas de calidad
- Log de decisiones tomadas (quÃ© se eliminÃ³ y por quÃ©)

## â±ï¸ **Tiempo Estimado**: 10-15 minutos